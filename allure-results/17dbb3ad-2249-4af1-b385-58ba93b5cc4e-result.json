{"name": "Case selection page loads and displays correct content", "status": "failed", "statusDetails": {"message": "AssertionError: MAJOR BUG: Incorrect Score! Expected score to be 0, but score displayed on page is 5/27/24.\n", "trace": "  File \"D:\\coding\\Testing\\Automation\\finding-the-truth-testing\\finding-the-truth-testing\\.venv\\lib\\site-packages\\behave\\model.py\", line 1329, in run\n    match.run(runner.context)\n  File \"D:\\coding\\Testing\\Automation\\finding-the-truth-testing\\finding-the-truth-testing\\.venv\\lib\\site-packages\\behave\\matchers.py\", line 98, in run\n    self.func(context, *args, **kwargs)\n  File \"features\\steps\\ui_case_selection_steps.py\", line 22, in step_assert_expected_score\n    case_selection_page.assert_score(expected_score)\n  File \"D:\\coding\\Testing\\Automation\\finding-the-truth-testing\\finding-the-truth-testing\\pages\\case_selection_page.py\", line 68, in assert_score\n    assert actual_score == expected_score, (f\"MAJOR BUG: Incorrect Score! Expected score to be {expected_score}, but \"\n"}, "steps": [{"name": "Given I navigate to the case selection page", "status": "passed", "start": 1716847729858, "stop": 1716847731990}, {"name": "Then case selection page header text is \"FINDING THE TRUTH\"", "status": "passed", "start": 1716847731990, "stop": 1716847732018}, {"name": "And page contains 2 cases to select from", "status": "passed", "start": 1716847732018, "stop": 1716847732039}, {"name": "And my score is \"0\"", "status": "failed", "statusDetails": {"message": "AssertionError: MAJOR BUG: Incorrect Score! Expected score to be 0, but score displayed on page is 5/27/24.\n", "trace": "  File \"D:\\coding\\Testing\\Automation\\finding-the-truth-testing\\finding-the-truth-testing\\.venv\\lib\\site-packages\\behave\\model.py\", line 1329, in run\n    match.run(runner.context)\n  File \"D:\\coding\\Testing\\Automation\\finding-the-truth-testing\\finding-the-truth-testing\\.venv\\lib\\site-packages\\behave\\matchers.py\", line 98, in run\n    self.func(context, *args, **kwargs)\n  File \"features\\steps\\ui_case_selection_steps.py\", line 22, in step_assert_expected_score\n    case_selection_page.assert_score(expected_score)\n  File \"D:\\coding\\Testing\\Automation\\finding-the-truth-testing\\finding-the-truth-testing\\pages\\case_selection_page.py\", line 68, in assert_score\n    assert actual_score == expected_score, (f\"MAJOR BUG: Incorrect Score! Expected score to be {expected_score}, but \"\n"}, "start": 1716847732039, "stop": 1716847732058}], "start": 1716847729857, "stop": 1716847732059, "uuid": "9887749b-922a-40e1-8cef-16e8f8b5852c", "historyId": "cea466bed503f4b890fd5649e3adb5b1", "fullName": "[UI TEST] Case selection: Case selection page loads and displays correct content", "labels": [{"name": "severity", "value": "normal"}, {"name": "feature", "value": "[UI TEST] Case selection"}, {"name": "framework", "value": "behave"}, {"name": "language", "value": "cpython3"}]}