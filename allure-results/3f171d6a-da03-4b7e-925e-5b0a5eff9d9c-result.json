{"name": "Case selection page loads and displays correct content", "status": "failed", "statusDetails": {"message": "AssertionError: MAJOR: Incorrect Score! Expected score to be 0, but score displayed on page is 5/27/24.\n", "trace": "  File \"D:\\coding\\Testing\\Automation\\finding-the-truth-testing\\finding-the-truth-testing\\.venv\\lib\\site-packages\\behave\\model.py\", line 1329, in run\n    match.run(runner.context)\n  File \"D:\\coding\\Testing\\Automation\\finding-the-truth-testing\\finding-the-truth-testing\\.venv\\lib\\site-packages\\behave\\matchers.py\", line 98, in run\n    self.func(context, *args, **kwargs)\n  File \"features\\steps\\ui_case_selection_steps.py\", line 22, in step_assert_expected_score\n    case_selection_page.assert_score(expected_score)\n  File \"D:\\coding\\Testing\\Automation\\finding-the-truth-testing\\finding-the-truth-testing\\pages\\case_selection_page.py\", line 69, in assert_score\n    assert actual_score == expected_score, (f\"MAJOR: Incorrect Score! Expected score to be {expected_score}, but \"\n"}, "steps": [{"name": "Given I navigate to the case selection page", "status": "passed", "start": 1716838287719, "stop": 1716838289836}, {"name": "Then case selection page header text is \"FINDING THE TRUTH\"", "status": "passed", "start": 1716838289837, "stop": 1716838289864}, {"name": "And page contains 2 cases to select from", "status": "passed", "start": 1716838289865, "stop": 1716838289887}, {"name": "And my score is \"0\"", "status": "failed", "statusDetails": {"message": "AssertionError: MAJOR: Incorrect Score! Expected score to be 0, but score displayed on page is 5/27/24.\n", "trace": "  File \"D:\\coding\\Testing\\Automation\\finding-the-truth-testing\\finding-the-truth-testing\\.venv\\lib\\site-packages\\behave\\model.py\", line 1329, in run\n    match.run(runner.context)\n  File \"D:\\coding\\Testing\\Automation\\finding-the-truth-testing\\finding-the-truth-testing\\.venv\\lib\\site-packages\\behave\\matchers.py\", line 98, in run\n    self.func(context, *args, **kwargs)\n  File \"features\\steps\\ui_case_selection_steps.py\", line 22, in step_assert_expected_score\n    case_selection_page.assert_score(expected_score)\n  File \"D:\\coding\\Testing\\Automation\\finding-the-truth-testing\\finding-the-truth-testing\\pages\\case_selection_page.py\", line 69, in assert_score\n    assert actual_score == expected_score, (f\"MAJOR: Incorrect Score! Expected score to be {expected_score}, but \"\n"}, "start": 1716838289887, "stop": 1716838289932}], "start": 1716838287718, "stop": 1716838289933, "uuid": "3a9f2522-d415-4347-8a9b-6d00deed5bb3", "historyId": "d451510ba8fdc43264337341725c37a7", "fullName": "Case selection: Case selection page loads and displays correct content", "labels": [{"name": "severity", "value": "normal"}, {"name": "feature", "value": "Case selection"}, {"name": "framework", "value": "behave"}, {"name": "language", "value": "cpython3"}]}